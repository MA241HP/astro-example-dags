"""
youtube_statistics
DAG auto-generated by Astro Cloud IDE.
"""

from airflow.decorators import dag
from airflow.models import Variable
from astro import sql as aql
import pandas as pd
import pendulum


@aql.dataframe(task_id="python_1")
def python_1_func():
    """
    youtube_statistics
    DAG auto-generated by Astro Cloud IDE.
    """
    
    from airflow.decorators import dag
    from airflow.models import Variable
    from astro import sql as aql
    import pandas as pd
    import pendulum
    
    
    @aql.dataframe(task_id="python_1")
    def python_1_func():
        from airflow import DAG
        from airflow.operators.python import PythonOperator
        from datetime import datetime
        from airflow.decorators import dag, task  # Import task decorator
        from airflow.models import Variable
        #import shutill
        #import os
        import pandas as pd
        import requests
        import snowflake.connector
        from snowflake.connector.pandas_tools import write_pandas
        
        
        
        @dag(
            dag_id="ntc_data_pipeline",
            start_date=datetime(2023, 1, 1),
            schedule_interval=None,  # Or specify your desired schedule
            catchup=False,
        )
        def ntc_data_pipeline_dag():
        
            @task
            def get_api_response_airflow():
                #url = "https://loadqa.ndapapi.com/v1/openapi?API_Key=gAAAAABnj28SY4m43zkgNBgokxqm2RIcTZWRd5uHUOOAeqNX6B1jE9Sm7kep6xiWUOMBm8p30dSUnQFg3sVfsA4Sa-_q5bAFpHpWUkVrttApy6HIijgkrPhjhtHHCm8JGamOW-qKkFVeX_jXdN65gf9yPJS1w0GVerN77kd7WecnRJaLPkjlJ52lt2sebsjvmZhS5H0tp2y2RMxMkG2hzwBzJ1sVkvNqcQ==&StateCode={'StateCode': 32}&CalendarDay={'CalendarDay: 2025-01-21'}&ind=I9131_4,I9131_5,I9131_6&dim=Country,StateName,StateCode,Year,CalendarDay&pageno=5"
                url = Variable.get("my_api_url")
                response = requests.get(url)
                try:
                    if response.status_code == 200:
                        print("hello")
                        response = response.json()
                        print(response)
                        return response
                    else:
                        return "no data"
                except Exception as e:
                    print(f"unable to connect {e}")
        
            @task
            def source_component_airflow(response):
                data = response.get("Data")
                pdf = pd.DataFrame(data)
                return pdf
        
            @task
            def transformation_component_airflow(pdf: pd.DataFrame):
                if not pdf.empty:
                    pdf["CalendarDay "] = pd.to_datetime(pdf["CalendarDay"])
                    pdf.rename(
                        columns={
                            "I9131_4": "Population",
                            "I9131_5": "no_of_e_transaction",
                            "I9131_6": "e_transaction_per_1000_population",
                        },
                        inplace=True,
                    )
                    pdf = pdf[pdf["CalendarDay"] >= "2025-01-01"].reset_index(
                        drop=True
                    )  # since boolean store under pdf
                    pdf["Population"] = pdf["Population"].apply(
                        lambda x: x.get("avg") if isinstance(x, dict) else None
                    )
                    pdf["no_of_e_transaction"] = pdf["no_of_e_transaction"].apply(
                        lambda row: row.get("avg") if isinstance(row, dict) else None
                    )
                    pdf["e_transaction_per_1000_population"] = pdf[
                        "e_transaction_per_1000_population"
                    ].apply(lambda row: row.get("avg") if isinstance(row, dict) else None)
                    print(pdf.to_string())
                    pdf.info()
                    return pdf
                else:
                    return "no data"
        
        
        
            # Define task dependencies using task objects and function calls
            get_api_response_task = get_api_response_airflow()
            source_component_task = source_component_airflow(get_api_response_task)
            transformation_component_task = transformation_component_airflow(source_component_task)
        
        
        # Create the DAG instance
        ntc_data_pipeline_dag_instance = ntc_data_pipeline_dag()
    
    default_args={
        "owner": "M. Azhar Ali,Open in Cloud IDE",
    }
    
    @dag(
        default_args=default_args,
        schedule="0 0 * * *",
        start_date=pendulum.from_format("2025-01-30", "YYYY-MM-DD").in_tz("UTC"),
        catchup=False,
        owner_links={
            "M. Azhar Ali": "mailto:muhalthaf.2580@gmail.com",
            "Open in Cloud IDE": "https://cloud.astronomer.io/cm6isj113047101ivie2g134u/cloud-ide/cm6ix8u1h04uo01l0zms13beg/cm6ixayyp057s01mdzfmft3pn",
        },
    )
    def youtube_statistics():
        python_1 = python_1_func()
    
    dag_obj = youtube_statistics()
    

default_args={
    "owner": "M. Azhar Ali,Open in Cloud IDE",
}

@dag(
    default_args=default_args,
    schedule="0 0 * * *",
    start_date=pendulum.from_format("2025-01-30", "YYYY-MM-DD").in_tz("UTC"),
    catchup=False,
    owner_links={
        "M. Azhar Ali": "mailto:muhalthaf.2580@gmail.com",
        "Open in Cloud IDE": "https://cloud.astronomer.io/cm6isj113047101ivie2g134u/cloud-ide/cm6ix8u1h04uo01l0zms13beg/cm6ixayyp057s01mdzfmft3pn",
    },
)
def youtube_statistics():
    python_1 = python_1_func()

dag_obj = youtube_statistics()
